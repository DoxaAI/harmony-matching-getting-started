{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Harmony**: Question Matching Algorithm Improvement Challenge\n",
    "\n",
    "**NLP challenge** | [Visit the challenge page](https://doxaai.com/competition/harmony-matching)\n",
    "\n",
    "Your challenge is to develop an improved algorithm for matching psychology survey questions that produces similarity ratings more closely aligned with those given by humans psychologists working in the field and that can be integrated into the [Harmony tool](https://harmonydata.ac.uk/developer-guide/).\n",
    "\n",
    "This Jupyter notebook will introduce you to the challenge and guide you through the process of making your first submission to the [DOXA AI platform](https://doxaai.com/competition/harmony-matching).\n",
    "\n",
    "**Before you get started, make sure to [sign up for an account](https://doxaai.com/sign-up) if you do not already have one and [enrol to take part](https://doxaai.com/competition/harmony-matching) in the challenge.**\n",
    "\n",
    "**If you have any questions, feel free to ask them in the [Harmony community Discord server](https://discord.com/invite/harmonydata).**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and importing useful packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas seaborn transformers sentence-transformers\n",
    "%pip install -U doxa-cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset if we do not already have it\n",
    "if not os.path.exists(\"train.csv\"):\n",
    "    !curl https://raw.githubusercontent.com/DoxaAI/harmony-matching-getting-started/main/train.csv --output train.csv\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data\n",
    "\n",
    "Let's get started by taking a look at the training dataset, which contains the following data variables:\n",
    "\n",
    "- `sentence_1` and `sentence_2`: a pair of English-language sentences drawn from psychology surveys\n",
    "- `human_similarity`: the human-judged similarity of the two sentences (integers in the range `[0, 100]`)\n",
    "- `cosine_from_harmony`: cosine similarity values currently generated by the Harmony tool, which are provided purely for reference and do not form part of the challenge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(12, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df, x=\"human_similarity\", y=\"cosine_from_harmony\", bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"human_similarity\", \"cosine_from_harmony\"]].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the visualisations and the correlation matrix, the cosine similarity scores currently being used within the Harmony tool do not correlate particularly well with the human-sourced similarity ratings. Your challenge is to develop a matching algorithm that aligns more closely with the human-provided scores!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating embeddings\n",
    "\n",
    "In this notebook, as an example to get you started, we are going to implement the relatively simple strategy of using a pre-trained model to compute sentence embeddings for each sentence in the training dataset and using the cosine similarity between the sentence pairs in the dataset as the basis for our similarity score predictions.\n",
    "\n",
    "First, we will load a pre-trained [SentenceTransformers](https://sbert.net/) model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use this to generate embeddings for all the sentence pairs in the training dataset and then compute the cosine similarity for each pair. Then, to produce similarity scores in the range `[0, 100]` to match the human-provided scores, we will slightly rescale and clip the cosine similarities we just computed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_1 = model.encode(df[\"sentence_1\"], normalize_embeddings=True)\n",
    "embeddings_2 = model.encode(df[\"sentence_2\"], normalize_embeddings=True)\n",
    "\n",
    "df[\"prediction\"] = model.similarity_pairwise(embeddings_1, embeddings_2)\n",
    "df[\"prediction\"] = (100 * df[\"prediction\"]).apply(int).clip(0, 100)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist([\"human_similarity\", \"prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df, x=\"human_similarity\", y=\"prediction\", bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"human_similarity\", \"cosine_from_harmony\", \"prediction\"]].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While these predictions represent a slight improvement, it is now your challenge to see how much better you can make things! ðŸ‘€\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Producing a submission package\n",
    "\n",
    "**Now, we will move onto creating your first submission!**\n",
    "\n",
    "When you upload your work to the DOXA AI platform, your code will be run in an environment with no internet access. As such, your submission needs to contain any models you want to use as part of the submission, as well as any code necessary to use those models.\n",
    "\n",
    "Currently, the `submission/` folder contains three files:\n",
    "\n",
    "- `submission/competition.py`: this contains competition-specific code used to interface with the platform\n",
    "- `submission/doxa.yaml`: this is a configuration file used by the DOXA CLI when you make a submission\n",
    "- `submission/run.py`: this is the Python script that gets run when your work gets evaluated (**you will need to edit this to implement your solution!**)\n",
    "\n",
    "First, we will save the SentenceTransformer model we have just loaded into our `submission/` directory:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"submission/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, if you take a look at `run.py`, you will see the following:\n",
    "\n",
    "```py\n",
    "class Evaluator(BaseEvaluator):\n",
    "    def predict(self, df: pd.DataFrame) -> Generator[int, Any, None]:\n",
    "        model = SentenceTransformer(str(directory / \"model\"))\n",
    "\n",
    "        embeddings_1 = model.encode(df[\"sentence_1\"], normalize_embeddings=True)\n",
    "        embeddings_2 = model.encode(df[\"sentence_2\"], normalize_embeddings=True)\n",
    "\n",
    "        df[\"prediction\"] = model.similarity_pairwise(embeddings_1, embeddings_2)\n",
    "        df[\"prediction\"] = (100 * df[\"prediction\"]).apply(int).clip(0, 100)\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            yield row[\"prediction\"]\n",
    "```\n",
    "\n",
    "In the `predict()` method, we load the `SentenceTransformer` model we just saved at `submission/model`, produce embeddings for the dataframe provided (in this instance containing the test set sentence pairs), compute the cosine similarities and then transform it into integer scores in the range `[0, 100]`. There are multiple ways to produce these similarity scores, and it is up to you to experiment with different techniques! For example, instead of computing the cosine similarity here, you may want to feed the embeddings you generate into another neural network you have trained for this task.\n",
    "\n",
    "**When you come to implement your own solution, you will need to edit `predict()` in `run.py` and make sure you include the right model in your submission!**\n",
    "\n",
    "You can modify `predict()` however you wish: it just has to yield your similarity score predictions in the same order as they appear in the dataframe. If your submission requires a lot of RAM, you may wish to modify `predict()` to process the test set in batches instead of all at once. Note that in addition to the RAM limit, there is a submission size limit, so make sure you are only uploading models that are relevant to your current submisison.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading your submission to the platform\n",
    "\n",
    "You are now ready to make your first submission to the platform! ðŸ‘€\n",
    "\n",
    "**Make sure to [enrol to take part](https://doxaai.com/competition/harmony-matching) in the challenge if you have not already done so.**\n",
    "\n",
    "First, we need to make sure we are logged in:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!doxa login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then, we can submit our work for evaluation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!doxa upload submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations!** ðŸ¥³\n",
    "\n",
    "By this point, you will now have just made your first submission for this challenge on the DOXA AI platform!\n",
    "\n",
    "If everything went well, your submission will now be queued up for evaluation. It will first be run on a small validation set to make sure that your submission does not crash on the full test set. If your submission runs into an issue at this point, you will be able to see the error logs from this phase. Otherwise, if your submission passes this stage, it will be evaluated on the full test set, and you will soon appear on the [competition scoreboard](https://doxaai.com/competition/harmony-matching/scoreboard)!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "**Now, it is up to you as to where you go from here to solve this challenge!**\n",
    "\n",
    "Here are some ideas you might want to test out:\n",
    "\n",
    "- Using other [SentenceTransformers](https://sbert.net/) models that may perform better at this task than `all-mpnet-base-v2`\n",
    "- Training an additional model to predict `human_similarity` from embeddings computed using the [SentenceTransformers](https://sbert.net/) library\n",
    "- Fine-tuning a language model for this task\n",
    "\n",
    "**We look forward to seeing what you build!** We would love to hear about what you are working on for this challenge, so do let us know how you are finding the challenge on the [Harmony community Discord server](https://discord.com/invite/harmonydata) or the [DOXA AI community Discord server](https://discord.gg/MUvbQ3UYcf). ðŸ˜Ž\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
